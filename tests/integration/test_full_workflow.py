"""Integration tests for full workflow."""

from datetime import UTC, datetime
from unittest.mock import AsyncMock, patch

import pytest

from repo_sapiens.engine.orchestrator import WorkflowOrchestrator
from repo_sapiens.models.domain import Issue, IssueState, Plan, Review, Task


@pytest.mark.asyncio
@pytest.mark.integration
async def test_complete_workflow(mock_settings, state_manager):
    """Test complete workflow from planning to PR via proposal stage.

    The 'needs-planning' label routes to the 'proposal' stage in the new workflow,
    which generates a plan and creates a proposal issue for review.
    """

    # Create mock providers
    mock_git = AsyncMock()
    mock_agent = AsyncMock()

    # Setup mock responses
    planning_issue = Issue(
        id=1,
        number=1,
        title="Test Feature",
        body="Implement test feature",
        state=IssueState.OPEN,
        labels=["needs-planning"],
        created_at=datetime.now(UTC),
        updated_at=datetime.now(UTC),
        author="testuser",
        url="https://example.com/issues/1",
    )

    # Mock plan generation
    plan = Plan(
        id="1",
        title="Test Feature",
        description="Test description",
        tasks=[
            Task(
                id="task-1",
                prompt_issue_id=1,
                title="Task 1",
                description="First task",
                dependencies=[],
            ),
            Task(
                id="task-2",
                prompt_issue_id=1,
                title="Task 2",
                description="Second task",
                dependencies=["task-1"],
            ),
        ],
        file_path="plans/1-test-feature.md",
        created_at=datetime.now(UTC),
    )

    mock_agent.generate_plan.return_value = plan
    mock_agent.generate_prompts.return_value = plan.tasks

    # Mock code review
    mock_agent.review_code.return_value = Review(
        approved=True,
        comments=["Looks good"],
        confidence_score=0.9,
    )

    # Mock git operations
    mock_git.add_comment.return_value = None
    mock_git.update_issue.return_value = None
    mock_git.commit_file.return_value = "abc123"

    # The proposal stage creates a new issue for the proposal
    proposal_issue = Issue(
        id=2,
        number=2,
        title="[PROPOSAL] Plan for #1: Test Feature",
        body="Review plan",
        state=IssueState.OPEN,
        labels=["proposed", "plan-for-1"],
        created_at=datetime.now(UTC),
        updated_at=datetime.now(UTC),
        author="bot",
        url="https://example.com/issues/2",
    )
    mock_git.create_issue.return_value = proposal_issue

    # Create orchestrator
    orchestrator = WorkflowOrchestrator(
        mock_settings,
        mock_git,
        mock_agent,
        state_manager,
    )

    # Process planning stage (routes to proposal stage)
    await orchestrator.process_issue(planning_issue)

    # Verify plan was generated by agent
    mock_agent.generate_plan.assert_called_once_with(planning_issue)

    # Verify proposal issue was created with correct labels
    mock_git.create_issue.assert_called_once()
    call_kwargs = mock_git.create_issue.call_args
    assert "proposed" in call_kwargs.kwargs["labels"]

    # Verify comments were added (initial notification + link to proposal)
    assert mock_git.add_comment.call_count >= 2

    # Verify original issue labels were updated (removed needs-planning, added awaiting-approval)
    mock_git.update_issue.assert_called()
    update_call = mock_git.update_issue.call_args
    assert "awaiting-approval" in update_call.kwargs["labels"]


@pytest.mark.asyncio
@pytest.mark.integration
async def test_parallel_task_execution(mock_settings, state_manager):
    """Test parallel execution of independent tasks.

    This test verifies the dependency-aware parallel execution logic in
    execute_parallel_tasks by patching _execute_single_task to avoid the
    complexity of mocking all the stage internals.
    """

    mock_git = AsyncMock()
    mock_agent = AsyncMock()

    # Create tasks with parallel execution potential:
    # task-1 and task-2 can run in parallel (no dependencies)
    # task-3 must wait for both task-1 and task-2 to complete
    tasks = [
        Task(id="task-1", prompt_issue_id=1, title="Task 1", description="First task", dependencies=[]),
        Task(id="task-2", prompt_issue_id=2, title="Task 2", description="Second task", dependencies=[]),
        Task(
            id="task-3", prompt_issue_id=3, title="Task 3", description="Third task", dependencies=["task-1", "task-2"]
        ),
    ]

    orchestrator = WorkflowOrchestrator(
        mock_settings,
        mock_git,
        mock_agent,
        state_manager,
    )

    # Track execution order to verify parallel behavior
    execution_order = []

    async def mock_execute_single_task(task, plan_id):
        """Mock task execution that records order."""
        execution_order.append(task.id)

    # Patch the internal method to avoid needing to mock all stage internals
    with patch.object(orchestrator, "_execute_single_task", side_effect=mock_execute_single_task):
        await orchestrator.execute_parallel_tasks(tasks, "test-plan")

    # Verify all 3 tasks were executed
    assert len(execution_order) == 3

    # Verify task-1 and task-2 were executed before task-3 (respecting dependencies)
    task_3_index = execution_order.index("task-3")
    task_1_index = execution_order.index("task-1")
    task_2_index = execution_order.index("task-2")
    assert task_1_index < task_3_index, "task-1 should execute before task-3"
    assert task_2_index < task_3_index, "task-2 should execute before task-3"


@pytest.mark.asyncio
@pytest.mark.integration
async def test_parallel_task_execution_with_stage_mocking(mock_settings, state_manager):
    """Test parallel execution with mocked stage execution.

    This test verifies the orchestrator's _execute_single_task method
    properly coordinates the implementation and code_review stages.
    We mock the stage execute methods to avoid their internal complexity.
    """

    mock_git = AsyncMock()
    mock_agent = AsyncMock()

    # Create tasks with proper issue references
    tasks = [
        Task(id="task-1", prompt_issue_id=101, title="Task 1", description="First task", dependencies=[]),
        Task(id="task-2", prompt_issue_id=102, title="Task 2", description="Second task", dependencies=[]),
        Task(
            id="task-3",
            prompt_issue_id=103,
            title="Task 3",
            description="Third task",
            dependencies=["task-1", "task-2"],
        ),
    ]

    # Create mock issues
    def make_mock_issue(task_id: str, issue_number: int) -> Issue:
        return Issue(
            id=issue_number,
            number=issue_number,
            title=f"[Implement] Task {task_id}",
            body=f"Task ID: {task_id}\nPart of plan #1",
            state=IssueState.OPEN,
            labels=["in-progress"],
            created_at=datetime.now(UTC),
            updated_at=datetime.now(UTC),
            author="bot",
            url=f"https://example.com/issues/{issue_number}",
        )

    mock_issues = {
        101: make_mock_issue("task-1", 101),
        102: make_mock_issue("task-2", 102),
        103: make_mock_issue("task-3", 103),
    }
    mock_git.get_issue.side_effect = lambda n: mock_issues.get(n)

    orchestrator = WorkflowOrchestrator(
        mock_settings,
        mock_git,
        mock_agent,
        state_manager,
    )

    # Track which stages were executed for which issues
    implementation_calls = []
    code_review_calls = []

    async def mock_implementation_execute(issue):
        implementation_calls.append(issue.number)

    async def mock_code_review_execute(issue):
        code_review_calls.append(issue.number)

    # Patch the stage execute methods
    orchestrator.stages["implementation"].execute = AsyncMock(side_effect=mock_implementation_execute)
    orchestrator.stages["code_review"].execute = AsyncMock(side_effect=mock_code_review_execute)

    # Execute tasks in parallel
    await orchestrator.execute_parallel_tasks(tasks, "1")

    # Verify implementation stage was called for all tasks
    assert len(implementation_calls) == 3
    assert set(implementation_calls) == {101, 102, 103}

    # Verify code review stage was called for all tasks
    assert len(code_review_calls) == 3
    assert set(code_review_calls) == {101, 102, 103}

    # Verify the order: task-3 (issue 103) should come after task-1 and task-2
    # Both lists should have 103 after 101 and 102
    assert implementation_calls.index(103) > implementation_calls.index(101)
    assert implementation_calls.index(103) > implementation_calls.index(102)
